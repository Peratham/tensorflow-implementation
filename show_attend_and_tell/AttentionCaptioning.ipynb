{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from solver import CaptioningSolver\n",
    "from model import CaptionGenerator\n",
    "from cs231n.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from cs231n.image_utils import image_from_url\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_to_word <type 'list'> 1004\n",
      "train_captions <type 'numpy.ndarray'> (100, 17) int32\n",
      "val_captions <type 'numpy.ndarray'> (195954, 17) int32\n",
      "train_image_idxs <type 'numpy.ndarray'> (100,) int32\n",
      "val_features <type 'numpy.ndarray'> (40504, 512) float32\n",
      "val_image_idxs <type 'numpy.ndarray'> (195954,) int32\n",
      "train_features <type 'numpy.ndarray'> (82783, 512) float32\n",
      "train_urls <type 'numpy.ndarray'> (82783,) |S63\n",
      "val_urls <type 'numpy.ndarray'> (40504,) |S63\n",
      "word_to_idx <type 'dict'> 1004\n"
     ]
    }
   ],
   "source": [
    "data = load_coco_data(max_train=100, pca_features=True)\n",
    "\n",
    "# Print out all the keys and values from the data dictionary\n",
    "for k, v in data.iteritems():\n",
    "    if type(v) == np.ndarray:\n",
    "        print k, type(v), v.shape, v.dtype\n",
    "    else:\n",
    "        print k, type(v), len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start word:  <START>\n"
     ]
    }
   ],
   "source": [
    "word_to_idx = data['word_to_idx']\n",
    "idx_to_word = {i: w for w, i in word_to_idx.iteritems()}\n",
    "small_data = sample_coco_minibatch(data, split='train', batch_size=100)  # get 100 train data\n",
    "train_captions, train_features, urls = small_data\n",
    "start_word = idx_to_word[train_captions[0,0]]\n",
    "print \"start word: \", start_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "with open(\"random_features.npy\", 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "# features = np.random.rand(100, 196, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['train_captions'] = data['train_captions'][0:100]\n",
    "data['train_features'] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CaptionGenerator(word_to_idx, batch_size= 100, dim_feature=[196, 512], dim_embed=128,\n",
    "                                   dim_hidden=128, n_time_step=16, cell_type='lstm', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver = CaptioningSolver(model, data, n_epochs=200, batch_size=100, update_rule='adam',\n",
    "                                      learning_rate=0.004, print_every=10, save_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epochs:  200\n",
      "n_iters_per_epoch:  1\n",
      "batch size:  100\n",
      "n_examples:  100\n",
      "Train Loss at Epoch 0: 6886.32031\n",
      "Generated Sentence: <START> a a a a a a a a a a a a a a a a\n",
      "Train Loss at Epoch 10: 4866.86719\n",
      "Generated Sentence: <START> a a a <END>\n",
      "Train Loss at Epoch 20: 4613.75684\n",
      "Generated Sentence: <START> a a a a a <END>\n",
      "Train Loss at Epoch 30: 4284.09473\n",
      "Generated Sentence: <START> a a a a a <UNK> <END>\n",
      "Train Loss at Epoch 40: 3930.74780\n",
      "Generated Sentence: <START> a <UNK> <UNK> <UNK> a <UNK> <END>\n",
      "Train Loss at Epoch 50: 3555.88525\n",
      "Generated Sentence: <START> a woman <UNK> on a <UNK> <END>\n",
      "Train Loss at Epoch 60: 3173.27417\n",
      "Generated Sentence: <START> a woman is on a <UNK> <END>\n",
      "Train Loss at Epoch 70: 2780.01270\n",
      "Generated Sentence: <START> a woman is on a <UNK> with a <UNK> <END>\n",
      "Train Loss at Epoch 80: 2385.41699\n",
      "Generated Sentence: <START> a man is on a <UNK> on a <UNK> board <END>\n",
      "Train Loss at Epoch 90: 2021.03479\n",
      "Generated Sentence: <START> a woman is on a <UNK> <END>\n",
      "Train Loss at Epoch 100: 1686.28040\n",
      "Generated Sentence: <START> a man standing on a <UNK> on a <UNK> board <END>\n",
      "Train Loss at Epoch 110: 1386.34790\n",
      "Generated Sentence: <START> a man standing on a <UNK> holding a <UNK> board <END>\n",
      "Train Loss at Epoch 120: 1139.76062\n",
      "Generated Sentence: <START> a woman standing on a <UNK> holding a surf board <END>\n",
      "Train Loss at Epoch 130: 923.55341\n",
      "Generated Sentence: <START> a woman standing on a beach holding a surf board <END>\n",
      "Train Loss at Epoch 140: 737.68188\n",
      "Generated Sentence: <START> a woman standing on a beach holding a surf board <END>\n",
      "Train Loss at Epoch 150: 588.66992\n",
      "Generated Sentence: <START> a person standing on a beach holding a surf board <END>\n",
      "Train Loss at Epoch 160: 468.38904\n",
      "Generated Sentence: <START> a person standing on a beach holding a surf board <END>\n",
      "Train Loss at Epoch 170: 375.12427\n",
      "Generated Sentence: <START> a person standing on a beach holding a surf board <END>\n",
      "Train Loss at Epoch 180: 301.26654\n",
      "Generated Sentence: <START> a person standing on a beach holding a surf board <END>\n",
      "Train Loss at Epoch 190: 245.41925\n",
      "Generated Sentence: <START> a person standing on a beach holding a surf board <END>\n"
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss, generated_captions = model.build_model()\n",
    "optimizer = tf.train.AdamOptimizer(0.004).minimize(loss)\n",
    "n_epoch = 2000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for e in range(n_epoch):\n",
    "        feed_dict =  {model.features: data['train_features'], model.captions: data['train_captions']}\n",
    "        _, gen_caps, l = sess.run([optimizer, generated_captions, loss], feed_dict)\n",
    "        if e % 10 == 0:\n",
    "            print \"loss at epoch %d: %.5f\" %(e, l)\n",
    "            decoded = decode_captions(gen_caps, model.idx_to_word)\n",
    "            print \"Generated Sentence: %s\" %decoded[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
